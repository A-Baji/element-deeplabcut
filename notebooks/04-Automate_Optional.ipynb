{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint U24 - Workflow DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Workflow Automation\n",
    "\n",
    "In the previous notebook [03-Process](./03-Process.ipynb), we ran through the workflow in detailed steps, manually adding each. The current notebook provides a more automated approach.\n",
    "\n",
    "The commands here run a workflow using example data from the [00-DownloadData](./00-DataDownload_Optional.ipynb) notebook, but note where placeholders could be changed for a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cbroz@dss-db.datajoint.io:3306\n"
     ]
    }
   ],
   "source": [
    "import os; from pathlib import Path\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='workflow-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"workflow directory\")\n",
    "from workflow_deeplabcut.pipeline import lab, subject, session, train, model\n",
    "from workflow_deeplabcut import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the `process.py` script to automatically loop through all `make` functions, as a shortcut for calling each individually.\n",
    "\n",
    "If you previously completed the [03-Process notebook](./03-Process.ipynb), you may want to delete the contents ingested there, to avoid duplication errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 4 rows from `u24_dlc_session`.`session_directory`\n",
      "Deleting 4 rows from `u24_dlc_session`.`session_note`\n",
      "Deleting 4 rows from `u24_dlc_session`.`session`\n",
      "Deleting 3 rows from `u24_dlc_train`.`#training_param_set`\n",
      "Deleting 0 rows from `u24_dlc_train`.`video_set`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safemode=True # Set to false to turn off confirmation prompts\n",
    "(session.Session & 'subject=\"subject6\"').delete(safemode=safemode)\n",
    "train.TrainingParamSet.delete(safemode=safemode)\n",
    "train.VideoSet.delete(safemode=safemode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion of subjects, sessions, videos and training parameters\n",
    "\n",
    "Refer to the `user_data` folder in the workflow.\n",
    "\n",
    "1. Fill subject and session information in files `subjects.csv` and `sessions.csv`\n",
    "2. Fill in recording and parameter information in `recordings.csv` and `config_params.csv`\n",
    "    + Add both training and estimation videos to the recording list\n",
    "    + Additional columns in `config_params.csv` will be treated as model training parameters\n",
    "3. Run automatic scripts prepared in `workflow_deeplabcut.ingest` for ingestion: \n",
    "    + `ingest_subjects` for `subject.Subject`\n",
    "    + `ingest_sessions` - for session tables `Session`, `SessionDirectory`, and `SessionNote`\n",
    "    + `ingest_dlc_items` - for ...\n",
    "        - `train.ModelTrainingParamSet`\n",
    "        - `train.VideoSet` and the corresponding `File` part table\n",
    "        - `model.VideoRecording` and the corresponding `File` part table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Inserting 0 entry(s) into subject ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session_directory ----\n",
      "\n",
      "---- Inserting 4 entry(s) into session_note ----\n",
      "\n",
      "---- Inserting 3 entry(s) into #model_training_param_set ----\n",
      "\n",
      "---- Inserting 3 entry(s) into video_set ----\n",
      "\n",
      "---- Inserting 10 entry(s) into video_set__file ----\n",
      "\n",
      "---- Inserting 1 entry(s) into video_recording ----\n",
      "\n",
      "---- Inserting 1 entry(s) into video_recording__file ----\n"
     ]
    }
   ],
   "source": [
    "from workflow_deeplabcut.ingest import ingest_subjects, ingest_sessions, ingest_dlc_items\n",
    "ingest_subjects()\n",
    "ingest_sessions()\n",
    "ingest_dlc_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting project variables\n",
    "\n",
    "1. Set your root directory in your DataJoint config file, under `custom` as `dlc_root_data_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj; dj.config.load('dj_local_conf.json')\n",
    "from element_interface.utils import find_full_path\n",
    "data_dir = find_full_path(dj.config['custom']['dlc_root_data_dir'], # root from config\n",
    "                          'from_top_tracking')                      # DLC project dir\n",
    "config_path = (data_dir / 'config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, we pair training files with training parameters, and launch training via `process`. \n",
    "   - Some tables may try to populate without upstream keys. \n",
    "   - Others, like `RecordingInfo` already have keys loaded.\n",
    "   - Note: DLC's model processes (e.g., Training, Evaluation) log a lot of information to the console, to quiet this, pass `verbose=False` to `process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.1.1...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['head', 'bodycenter', 'tailbase'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': '/Volumes/GoogleDrive/My '\n",
      "                 'Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/Documentation_data-from_top_tracking_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/tmp/test_data/from_top_tracking',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2022-07-18 18:44:31.514524: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained mobilenet_v2_1.0\n",
      "Max_iters overwritten as 5\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['head', 'bodycenter', 'tailbase'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': '/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/Documentation_data-from_top_tracking_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'mobilenet_v2_1.0', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': '/tmp/test_data/from_top_tracking', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 18:44:42.808440: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1380, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1363, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1456, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 970, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1193, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1373, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 1399, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue\n",
      " (defined at /Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py:69)\n",
      "]]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node fifo_queue_enqueue:\n",
      "In[0] fifo_queue (defined at /Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py:68)\t\n",
      "In[1] Placeholder (defined at /Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py:61)\t\n",
      "In[2] Placeholder_1:\t\n",
      "In[3] Placeholder_2:\t\n",
      "In[4] Placeholder_3:\t\n",
      "In[5] Placeholder_4:\n",
      "\n",
      "Operation defined at: (most recent call last)\n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      ">>>     return _run_code(code, main_globals, None,\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      ">>>     exec(code, run_globals)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      ">>>     app.launch_new_instance()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      ">>>     app.start()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 668, in start\n",
      ">>>     self.io_loop.start()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      ">>>     self.asyncio_loop.run_forever()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      ">>>     self._run_once()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      ">>>     handle._run()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      ">>>     self._context.run(self._callback, *self._args)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 456, in dispatch_queue\n",
      ">>>     await self.process_one()\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 445, in process_one\n",
      ">>>     await dispatch(*args)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 352, in dispatch_shell\n",
      ">>>     await result\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 647, in execute_request\n",
      ">>>     reply_content = await reply_content\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 335, in do_execute\n",
      ">>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      ">>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      ">>>     result = self._run_cell(\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      ">>>     return runner(coro)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      ">>>     coro.send(None)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      ">>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      ">>>     if (await self.run_code(code, result,  async_=asy)):\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      ">>>     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      ">>> \n",
      ">>>   File \"/var/folders/_9/tzvq__ws5z9gv5s7jvkj570r0000gn/T/ipykernel_35367/1370140438.py\", line 4, in <module>\n",
      ">>>     process.run(verbose=True, display_progress=True)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/Documents/dev/workflow-deeplabcut/workflow_deeplabcut/process.py\", line 43, in run\n",
      ">>>     table.populate(**populate_settings)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/datajoint/autopopulate.py\", line 229, in populate\n",
      ">>>     error = self._populate1(key, jobs, **populate_kwargs)\n",
      ">>> \n",
      ">>>   File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/datajoint/autopopulate.py\", line 281, in _populate1\n",
      ">>>     make(dict(key), **(make_kwargs or {}))\n",
      ">>> \n",
      ">>>   File \"/Users/cb/Documents/dev/element-deeplabcut/element_deeplabcut/train.py\", line 250, in make\n",
      ">>>     train_network(dlc_cfg_filepath, **train_network_kwargs)\n",
      ">>> \n",
      ">>>   File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 207, in train_network\n",
      ">>>     train(\n",
      ">>> \n",
      ">>>   File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      ">>>     batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      ">>> \n",
      ">>>   File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      ">>>     enqueue_op = q.enqueue(placeholders_list)\n",
      ">>> \n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 668, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 456, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 445, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 352, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 647, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 335, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_9/tzvq__ws5z9gv5s7jvkj570r0000gn/T/ipykernel_35367/1370140438.py\", line 4, in <module>\n",
      "    process.run(verbose=True, display_progress=True)\n",
      "  File \"/Users/cb/Documents/dev/workflow-deeplabcut/workflow_deeplabcut/process.py\", line 43, in run\n",
      "    table.populate(**populate_settings)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/datajoint/autopopulate.py\", line 229, in populate\n",
      "    error = self._populate1(key, jobs, **populate_kwargs)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/datajoint/autopopulate.py\", line 281, in _populate1\n",
      "    make(dict(key), **(make_kwargs or {}))\n",
      "  File \"/Users/cb/Documents/dev/element-deeplabcut/element_deeplabcut/train.py\", line 250, in make\n",
      "    train_network(dlc_cfg_filepath, **train_network_kwargs)\n",
      "  File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 207, in train_network\n",
      "    train(\n",
      "  File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"/Volumes/GoogleDrive/My Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 350, in enqueue\n",
      "    return gen_data_flow_ops.queue_enqueue_v2(\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 4063, in queue_enqueue_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n",
      "ModelTraining: 100%|██████████| 1/1 [00:29<00:00, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n",
      "\n",
      "---- Populating _recording_info ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordingInfo: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_evaluation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelEvaluation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __pose_estimation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Relation{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Relation th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Relation td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Relation tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "        }\n",
       "        .Relation tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b></b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Relation\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">subject</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">session_datetime</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">recording_id</p>\n",
       "                            <span class=\"djtooltiptext\"></span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">px_height</p>\n",
       "                            <span class=\"djtooltiptext\">height in pixels</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">px_width</p>\n",
       "                            <span class=\"djtooltiptext\">width in pixels</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">nframes</p>\n",
       "                            <span class=\"djtooltiptext\">number of frames</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">fps</p>\n",
       "                            <span class=\"djtooltiptext\">(Hz) frames per second</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">recording_datetime</p>\n",
       "                            <span class=\"djtooltiptext\">Datetime for the start of the recording</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">recording_duration</p>\n",
       "                            <span class=\"djtooltiptext\">video duration (s) from nframes / fps</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>subject6</td>\n",
       "<td>2021-06-02 14:04:22</td>\n",
       "<td>1</td>\n",
       "<td>500</td>\n",
       "<td>500</td>\n",
       "<td>123</td>\n",
       "<td>60</td>\n",
       "<td>None</td>\n",
       "<td>2.05</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 1</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*subject     *session_datet *recording_id  px_height     px_width     nframes     fps     recording_date recording_dura\n",
       "+----------+ +------------+ +------------+ +-----------+ +----------+ +---------+ +-----+ +------------+ +------------+\n",
       "subject6     2021-06-02 14: 1              500           500          123         60      None           2.05          \n",
       " (Total: 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key={'paramset_idx':0,'training_id':0,'video_set_id':0, \n",
    "     'project_path':'from_top_tracking/'}\n",
    "train.TrainingTask.insert1(key, skip_duplicates=True)\n",
    "process.run(verbose=True, display_progress=True)\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this demo, we'll want to use an older model, so the folling function will reload the original checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_deeplabcut.load_demo_data import revert_checkpoint_file\n",
    "revert_checkpoint_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now to add such a model upstream key\n",
    "   - Include a user-friendly `model_name`\n",
    "   - Include the relative path for the project's `config.yaml`\n",
    "   - Add `shuffle` and `trainingsetindex`\n",
    "   - `insert_new_model` will prompt before inserting, but this can be skipped with `prompt=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DLC Model specification to be inserted ---\n",
      "\tmodel_name: FromTop-latest\n",
      "\tmodel_description: FromTop - latest snapshot\n",
      "\tscorer: DLCmobnet100fromtoptrackingFeb23shuffle1\n",
      "\ttask: from_top_tracking\n",
      "\tdate: Feb23\n",
      "\titeration: 0\n",
      "\tsnapshotindex: -1\n",
      "\tshuffle: 1\n",
      "\ttrainingsetindex: 0\n",
      "\tproject_path: from_top_tracking\n",
      "\tparamset_idx: 1\n",
      "\t-- Template/Contents of config.yaml --\n",
      "\t\tTask: from_top_tracking\n",
      "\t\tscorer: DJ\n",
      "\t\tdate: Feb23\n",
      "\t\tvideo_sets: {'/tmp/test_data/from_top_tracking/videos/train1.mp4': {'crop': '0, 500, 0, 500'}}\n",
      "\t\tbodyparts: ['head', 'bodycenter', 'tailbase']\n",
      "\t\tstart: 0\n",
      "\t\tstop: 1\n",
      "\t\tnumframes2pick: 20\n",
      "\t\tpcutoff: 0.6\n",
      "\t\tdotsize: 3\n",
      "\t\talphavalue: 0.7\n",
      "\t\tcolormap: viridis\n",
      "\t\tTrainingFraction: [0.95]\n",
      "\t\titeration: 0\n",
      "\t\tdefault_net_type: resnet_50\n",
      "\t\tsnapshotindex: -1\n",
      "\t\tbatch_size: 8\n",
      "\t\tcropping: False\n",
      "\t\tx1: 0\n",
      "\t\tx2: 640\n",
      "\t\ty1: 277\n",
      "\t\ty2: 624\n",
      "\t\tcorner2move2: [50, 50]\n",
      "\t\tmove2corner: True\n",
      "\t\tcroppedtraining: None\n",
      "\t\tdefault_augmenter: default\n",
      "\t\tidentity: None\n",
      "\t\tmaxiters: 5\n",
      "\t\tmodelprefix: \n",
      "\t\tmultianimalproject: False\n",
      "\t\tscorer_legacy: False\n",
      "\t\tshuffle: 1\n",
      "\t\tskeleton: [['bodypart1', 'bodypart2'], ['objectA', 'bodypart3']]\n",
      "\t\tskeleton_color: black\n",
      "\t\ttrain_fraction: 0.95\n",
      "\t\ttrainingsetindex: 0\n",
      "\t\tproject_path: /tmp/test_data/from_top_tracking\n",
      "\n",
      "---- Populating __model_training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating _recording_info ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordingInfo: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_evaluation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelEvaluation:   0%|          | 0/1 [00:00<?, ?it/s]Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['head', 'bodycenter', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Volumes/GoogleDrive/My '\n",
      "                 'Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "ModelEvaluation: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_mobnet_100_from_top_trackingFeb23shuffle1_103000  with # of training iterations: 103000\n",
      "This net has already been evaluated!\n",
      "\n",
      "---- Populating __pose_estimation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.Model.insert_new_model(model_name='FromTop-latest', \n",
    "                             dlc_config=config_path,\n",
    "                             shuffle=1,\n",
    "                             trainingsetindex=0,\n",
    "                             paramset_idx=1, \n",
    "                             prompt=True, # True is the default behavior\n",
    "                             model_description='FromTop - latest snapshot',\n",
    "                             params={\"snapshotindex\":-1})\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add a pose estimation task, and launch via `process`.\n",
    "   - Get all primary key information for a given recording\n",
    "   - Add the model and `task_mode` (i.e., load vs. trigger) to be applied\n",
    "   - Add any additional analysis parameters for `deeplabcut.analyze_videos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTraining: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating _recording_info ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RecordingInfo: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __model_evaluation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelEvaluation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Populating __pose_estimation ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation:   0%|          | 0/1 [00:00<?, ?it/s]Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['head', 'bodycenter', 'tailbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_from_top_trackingFeb23/from_top_tracking_DJ95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/Volumes/GoogleDrive/My '\n",
      "                 'Drive/ref/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-103000 for model /tmp/test_data/from_top_tracking/dlc-models/iteration-0/from_top_trackingFeb23-trainset95shuffle1\n",
      "Starting to analyze %  /tmp/test_data/from_top_tracking/videos/test-2s.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PoseEstimation: 100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n"
     ]
    }
   ],
   "source": [
    "key=(model.VideoRecording & 'recording_id=1').fetch1('KEY')\n",
    "key.update({'model_name': 'FromTop-latest', 'task_mode': 'trigger'})\n",
    "analyze_params={'save_as_csv':True} # add any others from deeplabcut.analyze_videos\n",
    "model.PoseEstimationTask.insert_estimation_task(key,params=analyze_params)\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Retrieve estimated position data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"12\" halign=\"left\">FromTop-latest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"4\" halign=\"left\">bodycenter</th>\n",
       "      <th colspan=\"4\" halign=\"left\">head</th>\n",
       "      <th colspan=\"4\" halign=\"left\">tailbase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246.782684</td>\n",
       "      <td>298.728088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>241.036957</td>\n",
       "      <td>316.332489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>256.203064</td>\n",
       "      <td>278.553314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246.217529</td>\n",
       "      <td>299.358063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>239.048737</td>\n",
       "      <td>319.177002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>255.819626</td>\n",
       "      <td>280.200745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.459579</td>\n",
       "      <td>301.309235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>240.238800</td>\n",
       "      <td>320.525696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>255.705093</td>\n",
       "      <td>280.939056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242.014755</td>\n",
       "      <td>302.865204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>238.536774</td>\n",
       "      <td>322.324463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>254.424484</td>\n",
       "      <td>282.015778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.900177</td>\n",
       "      <td>303.459167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>237.967987</td>\n",
       "      <td>324.072327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>252.180603</td>\n",
       "      <td>280.899200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>248.682251</td>\n",
       "      <td>364.709869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>270.854980</td>\n",
       "      <td>371.893127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>234.899185</td>\n",
       "      <td>356.035583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>250.326385</td>\n",
       "      <td>366.870361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>271.488495</td>\n",
       "      <td>373.099884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>235.644073</td>\n",
       "      <td>356.815125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>251.634140</td>\n",
       "      <td>367.709198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>272.043884</td>\n",
       "      <td>373.402893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>236.953812</td>\n",
       "      <td>358.651459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>255.393692</td>\n",
       "      <td>364.111145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>273.417572</td>\n",
       "      <td>373.906799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>238.825363</td>\n",
       "      <td>361.561798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>257.736847</td>\n",
       "      <td>365.264008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>276.008667</td>\n",
       "      <td>373.901245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>239.148163</td>\n",
       "      <td>364.029297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer    FromTop-latest                                                      \\\n",
       "bodyparts     bodycenter                                    head               \n",
       "coords                 x           y    z likelihood           x           y   \n",
       "0             246.782684  298.728088  0.0   0.999998  241.036957  316.332489   \n",
       "1             246.217529  299.358063  0.0   0.999997  239.048737  319.177002   \n",
       "2             244.459579  301.309235  0.0   0.999999  240.238800  320.525696   \n",
       "3             242.014755  302.865204  0.0   0.999999  238.536774  322.324463   \n",
       "4             240.900177  303.459167  0.0   0.999998  237.967987  324.072327   \n",
       "..                   ...         ...  ...        ...         ...         ...   \n",
       "118           248.682251  364.709869  0.0   0.999965  270.854980  371.893127   \n",
       "119           250.326385  366.870361  0.0   0.999972  271.488495  373.099884   \n",
       "120           251.634140  367.709198  0.0   0.999972  272.043884  373.402893   \n",
       "121           255.393692  364.111145  0.0   0.999979  273.417572  373.906799   \n",
       "122           257.736847  365.264008  0.0   0.999996  276.008667  373.901245   \n",
       "\n",
       "scorer                                                             \n",
       "bodyparts                    tailbase                              \n",
       "coords       z likelihood           x           y    z likelihood  \n",
       "0          0.0   0.999850  256.203064  278.553314  0.0   0.999998  \n",
       "1          0.0   0.999905  255.819626  280.200745  0.0   0.999996  \n",
       "2          0.0   0.999899  255.705093  280.939056  0.0   0.999995  \n",
       "3          0.0   0.999941  254.424484  282.015778  0.0   0.999990  \n",
       "4          0.0   0.999941  252.180603  280.899200  0.0   0.999977  \n",
       "..         ...        ...         ...         ...  ...        ...  \n",
       "118        0.0   0.999961  234.899185  356.035583  0.0   0.999996  \n",
       "119        0.0   0.999991  235.644073  356.815125  0.0   0.999989  \n",
       "120        0.0   0.999995  236.953812  358.651459  0.0   0.999977  \n",
       "121        0.0   0.999997  238.825363  361.561798  0.0   0.999885  \n",
       "122        0.0   0.999992  239.148163  364.029297  0.0   0.999962  \n",
       "\n",
       "[123 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.PoseEstimation.get_trajectory(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next step\n",
    "\n",
    "+ This notebook runs through the workflow in an automatic manner.\n",
    "\n",
    "+ The next notebook [05-Visualization](./05-Visualization_Optional.ipynb) demonstrates how to plot this data and label videos on disk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "61456c693db5d9aa6731701ec9a9b08ab88a172bee0780139a3679beb166da16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
