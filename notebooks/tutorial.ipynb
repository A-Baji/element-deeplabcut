{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint Element for Pose Estimation with DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open-source Data Pipeline for Markerless Pose Estimation in Neurophysiology**\n",
    "\n",
    "This tutorial focuses on providing a comprehensive understanding of the open-source data pipeline offered by `Element-DeepLabCut`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/flowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package is designed to facilitate pose estimation analyses and streamline the organization of data using `DataJoint`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this tutorial, participants will have a clear grasp of how to set up, utilize, ad optimize the package for their specific pose estimation projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components and Objectives**\n",
    "\n",
    "- Setup\n",
    "\n",
    "- Design the DataJoint Pipeline\n",
    "\n",
    "- Step 1 - Register an existing model in DataJoint pipeline\n",
    "\n",
    "- Step 2 - Insert Subject, Session, and Behavior Videos\n",
    "\n",
    "- Step 3 - DLC inference task\n",
    "\n",
    "- Step 4 - Visualization of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detailed documentation and tutorials on general DataJoint principles that support collaboration, automation, reproducibility, and visualizations:\n",
    "\n",
    "[`DataJoint for Python - Interactive Tutorials`](https://github.com/datajoint/datajoint-tutorials) - Fundamentals including table tiers, query operations, fetch operations, automated computations with the make function, etc.\n",
    "\n",
    "[`DataJoint for Python - Documentation`](https://datajoint.com/docs/core/datajoint-python/0.14/)\n",
    "\n",
    "[`DataJoint Element for DeepLabCut - Documentation`](https://datajoint.com/docs/elements/element-deeplabcut/0.2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to run the ElementÂ¶\n",
    "\n",
    "The Element assumes you:\n",
    "\n",
    "- Have a DLC project folder on your machine\n",
    "- Have labeled data in your DLC project folder\n",
    "\n",
    "This tutorial includes a DLC project folder with example data and its results in `example_data`. In the following tutorial consists of studying the behavior of a freely-moving mouse in an open-field environment. The objective is to extract pose estimations of the animal's head and tail base from video footage. This information can provide valuable insights into the animal's movements, postures, and interactions within the environment. The results of this Element example could be combined with other modalities to assemble a complete pipeline. \n",
    "\n",
    "After running this tutorial, you can try `Element-DeepLabCut` with your own dataset. To do so, create a new `DeepLabCut` folder with your own videos and a training dataset. Then, remember to change the path in the configuration file (`config.yaml`) in your new `DeepLabCut project` folder accordingly.\n",
    "\n",
    "#### Challenges\n",
    "**Complex Background**: The open field environment introduces complex backgrounds and varying lighting conditions, making accurate pose estimation challenging.\n",
    "\n",
    "**Multiple Body Parts**: Extracting the pose of multiple body parts (head, tail) adds complexity to the analysis due to potential occlusions and variations in appearance.\n",
    "\n",
    "**Data Management**: Managing the large volume of video data generated in the field and ensuring consistent annotation requires an efficient data pipeline.\n",
    "\n",
    "### Expected Outcomes\n",
    "Upon completing this tutorial, you will have acquired practical proficiency in employing the `Element-DeepLabCut` package to effectively tackle the complexities of pose estimation. \n",
    "\n",
    "This tutorial and sample dataset will serve as a practical foundation for your learning journey with the Element package, enabling you to apply these techniques to your own research projects. \n",
    "\n",
    "By integrating this element package with other Elements of DataJoint, you unlock a powerful data pipeline that provides numerous benefits for your research workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='element-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"element directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start by importing the packages necessary to run this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's connect to the database server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the DataJoint Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine multiple Elements into a pipeline\n",
    "\n",
    "Each DataJoint Element is a modular set of tables that can be combined into a complete pipeline.\n",
    "\n",
    "Each Element contains one or more modules, and each module declares its own schema in the database. Schemas are conceptually related sets of tables. \n",
    "\n",
    "This tutorial pipeline is assembled from four DataJoint Elements.\n",
    "\n",
    "| Element | Source Code | Documentation | Description |\n",
    "| -- | -- | -- | -- |\n",
    "| Element Lab | [Link](https://github.com/datajoint/element-lab) | [Link](https://datajoint.com/docs/elements/element-lab) | Lab management related information, such as Lab, User, Project, Protocol, Source. |\n",
    "| Element Animal | [Link](https://github.com/datajoint/element-animal) | [Link](https://datajoint.com/docs/elements/element-animal) | General subject meta data, genotype, and surgery information. |\n",
    "| Element Session | [Link](https://github.com/datajoint/element-session) | [Link](https://datajoint.com/docs/elements/element-session) | General information of experimental sessions. |\n",
    "| Element DeepLabCut | [Link](https://github.com/datajoint/element-deeplabcut) | [Link](https://datajoint.com/docs/elements/element-deeplabcut) | DataJoint schemas (Train and Model) for storing and running analysis of markerless pose estimation with DeepLabCut.\n",
    "\n",
    "The Elements are imported and activated in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_pipeline import lab, subject, session, train, model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By importing the modules for the first time, the schemas and tables will be created in the database.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.list_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject) \n",
    "    + dj.Diagram(lab) \n",
    "    + dj.Diagram(session) \n",
    "    + dj.Diagram(model) \n",
    "    + dj.Diagram(train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(model) + dj.Diagram(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Register an existing model in DataJoint pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DeepLabCut model is defined in a DLC-specific folder structure with a file named `config.yaml` that contains the specifications of a DLC model.\n",
    "\n",
    "To \"register\" this DLC model with DataJoint, you can just specify this config file. See example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_rel = \"./example_data/inbox/from_top_tracking-DataJoint-2023-10-11/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model.insert_new_model(model_name='from_top_tracking_model_test',\n",
    "                             dlc_config=config_file_rel,\n",
    "                             shuffle=1,\n",
    "                             trainingsetindex=0,\n",
    "                             model_description='Model in example data: from_top_tracking model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Insert Subject, Session, and Behavior Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject and Session tables\n",
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject6\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"hneih_E105\",\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the dictionary named \"session_keys\"\n",
    "session_keys = [\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-02 14:04:22\"),\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-03 14:43:10\"),\n",
    "]\n",
    "\n",
    "#Insert this dictionary in the Session table\n",
    "session.Session.insert(session_keys, skip_duplicates=True)\n",
    "session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VideoRecording\n",
    "recording_key = {'subject': 'subject6',\n",
    "       'session_datetime': '2021-06-02 14:04:22',\n",
    "       'recording_id': '1'}\n",
    "model.VideoRecording.insert1({**recording_key, 'device': 'Camera1'}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VideoRecording.File\n",
    "\n",
    "video_files = [\"./example_data/inbox/from_top_tracking-DataJoint-2023-10-11/videos/test.mp4\"]\n",
    "\n",
    "model.VideoRecording.File.insert({\n",
    "    **recording_key, \n",
    "    'file_id': v_idx, \n",
    "    'file_path': Path(f)} for v_idx, f in enumerate(video_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RecordingInfo\n",
    "model.RecordingInfo.populate()\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element DeepLabCut has the capability to train a new model as well. To train the network, we need to add the parameter set (`TrainingParamSet`) of the model training (`train`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dj.Diagram(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - DLC inference task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_key = {**recording_key, 'model_name': 'from_top_tracking_model_test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.insert1(\n",
    "    {**task_key,\n",
    "     'task_mode': 'load',\n",
    "     'pose_estimation_output_dir': './example_data/outbox/from_top_tracking-DataJoint-2023-10-11/videos/device_1_recording_1_model_from_top_tracking_100000_maxiters'\n",
    "     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PoseEstimation\n",
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results\n",
    "model.PoseEstimation.BodyPartPosition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (model.PoseEstimation.BodyPartPosition & task_key).fetch(format='frame').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(['frame_index', 'x_pos', 'y_pos', 'likelihood']).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_xy \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_level_values(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39misin([\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m])][model\u001b[39m.\u001b[39mModel\u001b[39m.\u001b[39mfetch1(\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m      3\u001b[0m df_xy\u001b[39m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m df_xy\u001b[39m.\u001b[39mplot()\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_xy = df.iloc[:, df.columns.get_level_values(2).isin([\"x\", \"y\"])][model.Model.fetch1(\"model_name\")]\n",
    "df_xy.mean()\n",
    "df_xy.plot().legend(loc=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = df_xy.copy()\n",
    "df_flat.columns = df_flat.columns.map('_'.join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig,ax=plt.subplots()\n",
    "df_flat.plot(x='Head_x',y='Head_y', ax=ax)\n",
    "df_flat.plot(x='Tailbase_x',y='Tailbase_y', ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
