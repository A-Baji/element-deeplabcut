{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint Element for Pose Estimation with DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open-source Data Pipeline for Markerless Pose Estimation in Neurophysiology**\n",
    "\n",
    "This tutorial aims to provide a comprehensive understanding of the open-source data pipeline by `Element-DeepLabCut`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/flowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package is designed to simplify pose estimation analyses and streamline data organization using `DataJoint`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this tutorial, participants will have a clear grasp of how to set up and apply the `Element DeepLabCut` for their specific pose estimation projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Components and Objectives**\n",
    "\n",
    "**- Setup**\n",
    "\n",
    "**- Designing the DataJoint Pipeline**\n",
    "\n",
    "**- Step 1: Register an Existing Model in the DataJoint Pipeline**\n",
    "\n",
    "**- Step 2: Insert Subject, Session, and Behavior Videos**\n",
    "\n",
    "**- Step 3: DeepLabCut Inference Task**\n",
    "\n",
    "**- Step 4: Visualization of Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detailed documentation and tutorials on general DataJoint principles that support collaboration, automation, reproducibility, and visualizations:\n",
    "\n",
    "[`DataJoint for Python - Interactive Tutorials`](https://github.com/datajoint/datajoint-tutorials) covers fundamentals, including table tiers, query operations, fetch operations, automated computations with the make function, and more.\n",
    "\n",
    "[`DataJoint for Python - Documentation`](https://datajoint.com/docs/core/datajoint-python/0.14/)\n",
    "\n",
    "[`DataJoint Element for DeepLabCut - Documentation`](https://datajoint.com/docs/elements/element-deeplabcut/0.2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial examines the behavior of a freely-moving mouse in an open-field environment. \n",
    "\n",
    "The goal is to extract pose estimations of the animal's head and tail base from video footage. \n",
    "\n",
    "This information offers valuable insights into the animal's movements, postures, and interactions within the environment. \n",
    "\n",
    "The results of this Element example can be combined with other modalities to create a complete data pipeline for your specific lab or study.\n",
    "\n",
    "#### Steps to Run the Element-DeepLabCut\n",
    "\n",
    "To run the Element, ensure that you have:\n",
    "\n",
    "- A DeepLabCut (DLC) project folder on your machine.\n",
    "\n",
    "- Labeled data in your DLC project folder.\n",
    "\n",
    "This tutorial includes a DLC project folder with example data and its results in `example_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='element-deeplabcut', (\"Please move to the \"\n",
    "                                                              + \"element directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start by importing the packages necessary to run this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codespace provides a local database private to you for experimentation. Let's connect to the database server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the DataJoint Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes that `element-deeplabcut` is already configured and instantiated, with the database connected downstream from existing subject and session tables. Import schemas for subject, session, train, model, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_pipeline import lab, subject, session, train, model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject) \n",
    "    + dj.Diagram(lab) \n",
    "    + dj.Diagram(session) \n",
    "    + dj.Diagram(model) \n",
    "    + dj.Diagram(train)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data pipeline is quite extensive, with various tables related to other components like models, training, and evaluation in DLC. Some, such as the `Subject` table, are not relevant to this tutorial and are upstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(model) + dj.Diagram(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diagram represents the `element-deeplabcut` pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Register an Existing Model in the DataJoint Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DeepLabCut model is defined in a specific folder structure with a `config.yaml` file that contains the model's specifications (see folder `example_data/inbox`). To \"register\" this DLC model with DataJoint, you can specify this config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_rel = \"./example_data/inbox/from_top_tracking-DataJoint-2023-10-11/config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `insert_new_model` function is a helper function provided in `element-deeplacut` for convenient model registration.\n",
    "\n",
    "This function prints out the essential information, like the `model_name` and the `model_description`, together with other relevant information from the config file. \n",
    "\n",
    "If all the information is correct, you can confirm the insertion by typing 'yes,' which will insert the new model and its two body parts, `head` and `tailbase`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model.insert_new_model(model_name='from_top_tracking_model_test',\n",
    "                             dlc_config=config_file_rel,\n",
    "                             shuffle=1,\n",
    "                             trainingsetindex=0,\n",
    "                             model_description='Model in example data: from_top_tracking model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `Model` table to confirm that the new model has been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this information is directly sourced from the `config` file. However, it's worth noting that this model is currently distinct and singular. \n",
    "\n",
    "If you wish to incorporate another model, you must specify a new `model_name`; duplication of an existing model is not permittedâ€”it must be an entirely new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Insert Subject, Session, and Behavior Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the availability of data in the `Subject` and `Session` tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert a subject into the `Subject` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject and Session tables\n",
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject6\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"hneih_E105\",\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define session keys and insert them into the `Session` table:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the dictionary named \"session_keys\"\n",
    "session_keys = [\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-02 14:04:22\"),\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-03 14:43:10\"),\n",
    "]\n",
    "\n",
    "#Insert this dictionary in the Session table\n",
    "session.Session.insert(session_keys, skip_duplicates=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the inserted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert data into the `VideoRecording` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VideoRecording\n",
    "recording_key = {'subject': 'subject6',\n",
    "       'session_datetime': '2021-06-02 14:04:22',\n",
    "       'recording_id': '1'}\n",
    "model.VideoRecording.insert1({**recording_key, 'device': 'Camera1'}, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert video files into the `VideoRecording.File` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VideoRecording.File\n",
    "\n",
    "video_files = [\"./example_data/inbox/from_top_tracking-DataJoint-2023-10-11/videos/train1.mp4\"]\n",
    "\n",
    "model.VideoRecording.File.insert({\n",
    "    **recording_key, \n",
    "    'file_id': v_idx, \n",
    "    'file_path': Path(f)} for v_idx, f in enumerate(video_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the `RecordingInfo` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RecordingInfo\n",
    "model.RecordingInfo.populate()\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording info extracts metadata from the video and validates the number of frames (n_frames), which will correspond to the number of entries for each body part in the pose estimation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - DeepLabCut Inference Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PoseEstimationTask` table is used for defining an inference task. Let's explore the table description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define and insert a task, you need to:\n",
    "\n",
    "1. Define a video recording.\n",
    "2. Select a model.\n",
    "3. Choose the task mode (load or trigger).\n",
    "4. Specify the output directory and optional parameters.\n",
    "\n",
    "When the task mode is \"trigger,\" DataJoint triggers the inference, running the DeepLabCut model. This might take a long time, depending on the hardware. If the hardware lacks GPU support, it's not recommended.\n",
    "\n",
    "For this exercise, we are choosing the **\"load\" task** mode because the server does not have the necessary GPU for inference. The results have already been prepared. The results of this inference are generated in `example_data\\outbox`. \n",
    "\n",
    "If you select the **\"trigger\" task**, DataJoint will perform the entire inference process and generate these file sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the keys for recording and task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_key = {**recording_key, 'model_name': 'from_top_tracking_model_test'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are located in the `pose_estimation_output_dir` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.insert1(\n",
    "    {**task_key,\n",
    "     'task_mode': 'load',\n",
    "     'pose_estimation_output_dir': './example_data/outbox/from_top_tracking-DataJoint-2023-10-11/videos/device_1_recording_1_model_from_top_tracking_100000_maxiters'\n",
    "     })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the `PoseEstimationTask` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PoseEstimation\n",
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the `PoseEstimation` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most critical table is the `PoseEstimation.BodyPartPosition`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Results\n",
    "model.PoseEstimation.BodyPartPosition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pose estimation, entries related to the task include `subject`, `session`, `recording_id`, `model name`, and each detected `body_part` (two entries in this case).\n",
    "\n",
    "Entries contain `frame_index`, `x_pos` and `y_pos` positions, and `likelihood` (`z_pos` is zero). This structure is familiar to DeepLabCut users.\n",
    "\n",
    "These results can be fetched in a Pandas DataFrame structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (model.PoseEstimation.BodyPartPosition & task_key).fetch(format='frame').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`frame_index` is an array of frame numbers, `x_pos` is a NumPy array of x positions, and `likelihood` is also a NumPy array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataJoint `fetch` as a Pandas DataFrame and utilize the `explode` function to expand `x` and `y` positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode(['frame_index', 'x_pos', 'y_pos', 'likelihood']).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, you can confirm these results by the number of entries. There are 66000 frames for each body part, matching the `n_frames` from the `RecordingInfo` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Visualization of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, separate the data for the head and tailbase and then plot the head pose estimation and tailbase pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "head_data = df[df['body_part'] == 'head']\n",
    "tail_data = df[df['body_part'] == 'tailbase']\n",
    "\n",
    "plt.title('Head pose estimation')\n",
    "plt.plot(head_data['x_pos'],label='x_pos')\n",
    "plt.plot(head_data['y_pos'],label='y_pos')\n",
    "plt.xlabel('time (frames)')\n",
    "plt.ylabel('pos (pixels)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Tailbase pose estimation')\n",
    "plt.plot(tail_data['x_pos'],label='x_pos')\n",
    "plt.plot(tail_data['y_pos'],label='y_pos')\n",
    "plt.xlabel('time (frames)')\n",
    "plt.ylabel('pos (pixels)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the head and tailbase positions on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(head_data['x_pos'], head_data['y_pos'], label='head')\n",
    "plt.plot(tail_data['x_pos'], tail_data['y_pos'], label='tailbase')\n",
    "plt.xlabel('x_pos (pixels)')\n",
    "plt.ylabel('y_pos (pixels)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
