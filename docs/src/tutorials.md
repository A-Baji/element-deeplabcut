# Tutorials

## Installation

Installation of the Element requires an integrated development environment and database.
Instructions to setup each of the components can be found on the 
[User Instructions](datajoint.com/docs/elements/user-instructions) page.  These 
instructions
use the example 
[workflow for Element DeepLabCut](https://github.com/datajoint/workflow-deeplabcut), 
which can be modified for a user's specific experimental requirements.  This example workflow uses four Elements (Lab, Animal, Session, and DeepLabCut) to construct a complete pipeline, and is able to ingest experimental metadata and run model training and inference.
## Steps to run the Element
## Videos

Our [Element DeepLabCut tutorial](https://www.youtube.com/watch?v=8FDjTuQ52gQ) gives an 
overview  of the workflow directory as well as core concepts related to DeepLabCut 
itself.

[![YouTube tutorial](https://img.youtube.com/vi/8FDjTuQ52gQ/0.jpg)](https://www.youtube.com/watch?v=8FDjTuQ52gQ)

## Notebooks

Each of the 
[notebooks](https://github.com/datajoint/workflow-deeplabcut/tree/main/notebooks) in 
the workflow steps through ways to interact with the Element itself. To try out Elements
notebooks in an online Jupyter environment with access to example data, visit 
[CodeBook](https://codebook.datajoint.io/). (DeepLabCut notebooks coming soon!)

- [00-DataDownload](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/00-DataDownload_Optional.ipynb) 
   highlights how to use DataJoint tools to download a sample model for trying out the Element.
- [01-Configure](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/01-Configure.ipynb) 
   helps configure your local DataJoint installation to point to the correct database.
- [02-WorkflowStructure](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/02-WorkflowStructure_Optional.ipynb)
   demonstrates the table architecture of the Element and key DataJoint basics for interacting with these tables.
- [03-Process](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/03-Process.ipynb) 
   steps through adding data to these tables and launching key DeepLabCut features, like model training.
- [04-Automate](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/04-Automate_Optional.ipynb) 
   highlights the same steps as above, but utilizing all built-in automation tools.
- [05-Visualization](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/05-Visualization_Optional.ipynb) 
   demonstrates how to fetch data from the Element to generate figures and label data.
- [06-Drop](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/06-Drop_Optional.ipynb) 
   provides the steps for dropping all the tables to start fresh.
- `07-NWB-Export` (coming soon!) will describe how to export into NWB files. For now, 
  see [below](#nwb-export)
- [09-AlternateDataset](https://github.com/datajoint/workflow-deeplabcut/blob/main/notebooks/09-AlternateDataset.ipynb)
   does all of the above, but with a 
   [dataset from DeepLabCut](https://github.com/DeepLabCut/DeepLabCut/tree/master/examples/openfield-Pranav-2018-10-30).

## Data Export to Neurodata Without Borders (NWB)

The `export/nwb.py` module calls [DLC2NWB](https://github.com/DeepLabCut/DLC2NWB/) to
save output generated by Element DeepLabCut as NWB files. 
The main function, `dlc_session_to_nwb`, contains a flag to control calling a parallel 
function in 
[Element Session](https://github.com/datajoint/element-session/blob/main/element_session/export/nwb.py).

Before using, please install [DLC2NWB](https://github.com/DeepLabCut/DLC2NWB/)

```console
pip install dlc2nwb
```

Then, call the export function using keys from the `PoseEstimation` table.

```python
from element_deeplabcut import model
from element_session import session
from element_deeplabcut.export import dlc_session_to_nwb

session_key = (session.Session & CONDITION)
pose_key = (model.PoseEstimation & session_key).fetch1('KEY')
dlc_session_to_nwb(pose_key, use_element_session=True, session_kwargs=SESSION_KWARGS)
```

Here, `CONDITION` should uniquely identify a session and `SESSION_KWARGS` can be any of
the items described in the docstring of `element_session.export.nwb.session_to_nwb`
as a dictionary.

As DLC2NWB does not currently offer a separate function for generating `PoseEstimation`
objects (see [ndx-pose](https://github.com/rly/ndx-pose)), the current solution is to
allow DLC2NWB to write to disk, and optionally rewrite this file using metadata provided
by the export function in Element Session.